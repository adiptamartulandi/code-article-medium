{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "beeb833dd9194a569b20f20ac978deeb": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_6289cfd249ec4be39454f3b42ebb10f5",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[38;2;106;0;255m⠙\u001b[0m ✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o, strict=False, async_mode=True)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">⠙</span> ✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o, strict=False, async_mode=True)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "6289cfd249ec4be39454f3b42ebb10f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f9123f146d4032a6a1085342318319": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_1d072616d9ea45dfaa732cb3c4f84d4f",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[38;2;106;0;255m⠙\u001b[0m ✨ You're running DeepEval's latest \u001b[38;2;106;0;255mHallucination Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o, strict=False, async_mode=False)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">⠙</span> ✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Hallucination Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o, strict=False, async_mode=False)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "1d072616d9ea45dfaa732cb3c4f84d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c7c336cd13c4c928bd98a84e2778144": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_d3d2da9ea83b4a978c16b6694be583b6",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[38;2;106;0;255m⠏\u001b[0m ✨ You're running DeepEval's latest \u001b[38;2;106;0;255mPrompt Alignment Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o, strict=False, async_mode=True)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">⠏</span> ✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Prompt Alignment Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o, strict=False, async_mode=True)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "d3d2da9ea83b4a978c16b6694be583b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a9c3e900ba4f0b9c0eb6d85969f0a9": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_20f9e711a40a4dcf81da5bd8f2cba356",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[38;2;106;0;255m⠦\u001b[0m ✨ You're running DeepEval's latest \u001b[38;2;106;0;255mCorrectness (GEval) Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o, strict=False, async_mode=True)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">⠦</span> ✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Correctness (GEval) Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o, strict=False, async_mode=True)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "20f9e711a40a4dcf81da5bd8f2cba356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain_openai langchain_core langchain deepeval watermark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kGK8-3rgF2Vw",
        "outputId": "ddd14c8f-2a6a-4f07-a50c-d9a953d10146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SzGUSZ4EXAt"
      },
      "outputs": [],
      "source": [
        "#import dependencies\n",
        "import os\n",
        "\n",
        "from watermark import watermark\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "from deepeval import evaluate\n",
        "from deepeval.metrics import (\n",
        "    AnswerRelevancyMetric, HallucinationMetric,\n",
        "    PromptAlignmentMetric, GEval\n",
        "    )\n",
        "from deepeval.test_case import LLMTestCase, LLMTestCaseParams"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set envar for API key\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY4')"
      ],
      "metadata": {
        "id": "IojNCw92Fi8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "GamuzwF7Gr7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create openai chat model\n",
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "# create basic string output parser\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# create prompt template\n",
        "system_template = \"\"\"\n",
        "    You are a personal assistant that help answer question from user,\n",
        "    Here is the user question: {question}\n",
        "    \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{question}\")]\n",
        ")\n",
        "\n",
        "# using LCEL to create chain\n",
        "chain = prompt_template | model | parser"
      ],
      "metadata": {
        "id": "_5Rqt_jeGsui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "- we will try 4 metrics from deepeval\n",
        "  - Answer Relevancy\n",
        "  - Hallucination\n",
        "  - Prompt Alignment\n",
        "  - G-Eval"
      ],
      "metadata": {
        "id": "P8GGrKfvGDrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer Relevancy\n",
        "- required arguments\n",
        "  - input\n",
        "  - actual_output"
      ],
      "metadata": {
        "id": "9WHWrmmVGZf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# invoke the chain\n",
        "llm_result = chain.invoke({\"question\": \"what is the different between NLU and NLG in NLP ?\"})\n",
        "llm_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "lVN08dr5HE_a",
        "outputId": "0c3f72be-0f96-4f53-8243-945b8cfe8613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"In Natural Language Processing (NLP), Natural Language Understanding (NLU) and Natural Language Generation (NLG) are two distinct components that serve different purposes:\\n\\n1. **Natural Language Understanding (NLU):**\\n   - **Purpose:** NLU focuses on comprehending and interpreting human language input. It involves analyzing the structure and meaning of the language to extract meaningful information.\\n   - **Key Tasks:** These include tasks like intent recognition, entity extraction, sentiment analysis, and language comprehension.\\n   - **Examples:** When you ask a virtual assistant a question, NLU is responsible for understanding what you are asking and identifying the relevant details.\\n\\n2. **Natural Language Generation (NLG):**\\n   - **Purpose:** NLG is concerned with creating human-like language responses from structured data or information. It focuses on the production of text that is both coherent and contextually appropriate.\\n   - **Key Tasks:** These include tasks like text summarization, report generation, dialogue generation, and creating descriptions or narratives.\\n   - **Examples:** When a chatbot responds to your query with a coherent sentence or when a system generates a weather report, NLG is at work.\\n\\nIn summary, NLU is about understanding language, while NLG is about producing language. These components often work together in applications like chatbots and virtual assistants, where understanding the user's input (NLU) and generating a response (NLG) are both essential.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = AnswerRelevancyMetric(\n",
        "    threshold=0.7,\n",
        "    model=\"gpt-4o\",\n",
        "    include_reason=True\n",
        ")\n",
        "test_case = LLMTestCase(\n",
        "    input=\"what is the different between NLU and NLG in NLP ?\",\n",
        "    actual_output=llm_result\n",
        ")\n",
        "\n",
        "metric.measure(test_case)\n",
        "print(metric.score)\n",
        "print(metric.reason)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88,
          "referenced_widgets": [
            "beeb833dd9194a569b20f20ac978deeb",
            "6289cfd249ec4be39454f3b42ebb10f5"
          ]
        },
        "id": "PoVEHRvgFlGT",
        "outputId": "d0e19a6e-242c-454a-817f-54b170a246c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "beeb833dd9194a569b20f20ac978deeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "The score is 1.00 because the response perfectly addresses the distinction between NLU (Natural Language Understanding) and NLG (Natural Language Generation) in NLP with complete relevance and focus. Fantastic job!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hallucination\n",
        "- required arguments:\n",
        "  - input\n",
        "  - actual_output\n",
        "  - context"
      ],
      "metadata": {
        "id": "sp5desU3SgQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# invoke the chain\n",
        "llm_result = chain.invoke({\"question\": \"what is the The Witcher 4 from CD Projekt Red ?\"})\n",
        "llm_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "V1X6CyNNS1O9",
        "outputId": "fc2d16c7-86b3-4b8c-95ff-300d0973364e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As of my last update in October 2023, CD Projekt Red has announced the development of a new game in The Witcher series, often referred to by fans and media as \"The Witcher 4.\" However, the official title and specific details about the game have not been fully disclosed. CD Projekt Red has confirmed that this new installment will mark the beginning of a new saga in The Witcher universe, indicating that it may explore new storylines and characters beyond those of Geralt of Rivia, the protagonist of the previous games. The game will be developed using Unreal Engine 5, which suggests significant advancements in graphics and gameplay capabilities. Further details, including release date, plot, and setting, are expected to be revealed closer to the game\\'s launch.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace this with the actual documents that you are passing as input to your LLM.\n",
        "context=[\"The Witcher IV is an upcoming action role-playing game developed by CD Projekt Red and published by CD Projekt. It is the planned first installment of a new trilogy in The Witcher series and is set several years after the events of The Witcher 3: Wild Hunt.\"]\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "    input=\"what is the The Witcher 4 from CD Projekt Red ?\",\n",
        "    actual_output=llm_result,\n",
        "    context=context\n",
        ")\n",
        "metric = HallucinationMetric(threshold=0.5)\n",
        "\n",
        "metric.measure(test_case)\n",
        "print(metric.score)\n",
        "print(metric.reason)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72,
          "referenced_widgets": [
            "61f9123f146d4032a6a1085342318319",
            "1d072616d9ea45dfaa732cb3c4f84d4f"
          ]
        },
        "id": "1lqvOCRlSc-U",
        "outputId": "5942f6d8-41a0-4e61-8aaa-b39c37f535f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61f9123f146d4032a6a1085342318319"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "The score is 0.00 because the actual output fully aligns with the context without any contradictions, confirming the development of a new game in The Witcher series by CD Projekt Red as stated in the context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Alignment\n",
        "- required arguments\n",
        "  - input\n",
        "  - actual_output"
      ],
      "metadata": {
        "id": "h4S5Q8glT68r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create prompt template\n",
        "system_template_prompt_alignment = \"\"\"\n",
        "    You are a personal assistant that translate input from user to french language,\n",
        "    Here is the user input: {input}\n",
        "    \"\"\"\n",
        "\n",
        "prompt_template_alignment = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template_prompt_alignment), (\"user\", \"{input}\")]\n",
        ")\n",
        "\n",
        "# using LCEL to create chain\n",
        "chain_prompt_alignment = prompt_template_alignment | model | parser"
      ],
      "metadata": {
        "id": "C82LkCSrUSni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# invoke the chain\n",
        "llm_result = chain_prompt_alignment.invoke({\"input\": \"Hello how are you today ?\"})\n",
        "llm_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nD0HX2MDUdhK",
        "outputId": "6d8a3bca-e59b-46fc-9aa5-8922730000af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Bonjour, comment allez-vous aujourd'hui ?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = PromptAlignmentMetric(\n",
        "    prompt_instructions=[\"You are a personal assistant that translate input from user to italian language\"],\n",
        "    model=\"gpt-4o\",\n",
        "    include_reason=True\n",
        ")\n",
        "test_case = LLMTestCase(\n",
        "    input=\"Hello how are you today ?\",\n",
        "    actual_output=llm_result\n",
        ")\n",
        "\n",
        "metric.measure(test_case)\n",
        "print(metric.score)\n",
        "print(metric.reason)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "9c7c336cd13c4c928bd98a84e2778144",
            "d3d2da9ea83b4a978c16b6694be583b6"
          ]
        },
        "id": "4PXCh--UT61o",
        "outputId": "71d2f24b-2e89-4d82-a57f-72a62a8d8a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c7c336cd13c4c928bd98a84e2778144"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "The score is 0.00 because the LLM translated the input to French instead of Italian, not aligning with the specified prompt instructions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### G-Eval\n",
        "- required arguments\n",
        "  - input\n",
        "  - actual_output"
      ],
      "metadata": {
        "id": "2QHC6vOAU8wZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# invoke the chain\n",
        "llm_result = chain.invoke({\"question\": \"what is the The Witcher 4 from CD Projekt Red ?\"})\n",
        "llm_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "BtjqcrbFVkby",
        "outputId": "9b696151-7618-46b3-c26d-5e7042f926f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"The Witcher 4\" is a highly anticipated project from CD Projekt Red, the developers behind the critically acclaimed Witcher series. While the game is not officially titled \"The Witcher 4,\" CD Projekt Red announced in March 2022 that they are working on a new installment in The Witcher series. This new game will kick off a new saga in the Witcher universe, separate from the original trilogy that followed the story of Geralt of Rivia.\\n\\nThe game is expected to be developed using Unreal Engine 5, marking a shift from the company\\'s proprietary REDengine technology. This decision is part of a strategic partnership with Epic Games. Details about the plot, characters, and setting of this new Witcher game have not been fully disclosed as of October 2023. However, fans can expect the same rich storytelling, deep world-building, and immersive gameplay that the series is known for.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expected_output=[\"The Witcher IV is an upcoming action role-playing game developed by CD Projekt Red and published by CD Projekt. It is the planned first installment of a new trilogy in The Witcher series and is set several years after the events of The Witcher 3: Wild Hunt.\"]\n",
        "\n",
        "correctness_metric = GEval(\n",
        "    name=\"Correctness\",\n",
        "    criteria=\"Determine whether the actual output is factually correct based on the expected output.\",\n",
        "    evaluation_steps=[\n",
        "        \"Check whether the facts in 'actual output' contradicts any facts in 'expected output'\",\n",
        "        \"You should also heavily penalize if the actual output not correct based on expected outpur\",\n",
        "        \"Vague language, or contradicting OPINIONS, are OK\"\n",
        "    ],\n",
        "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
        ")\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "    input=\"what is the The Witcher 4 from CD Projekt Red ?\",\n",
        "    actual_output=llm_result,\n",
        "    expected_output=expected_output\n",
        ")\n",
        "\n",
        "correctness_metric.measure(test_case)\n",
        "print(correctness_metric.score)\n",
        "print(correctness_metric.reason)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88,
          "referenced_widgets": [
            "69a9c3e900ba4f0b9c0eb6d85969f0a9",
            "20f9e711a40a4dcf81da5bd8f2cba356"
          ]
        },
        "id": "l4XJMbdKTj5G",
        "outputId": "8f4cdf9a-cf9d-45ed-8876-60b0be25c56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69a9c3e900ba4f0b9c0eb6d85969f0a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7698826271357894\n",
            "The actual output aligns with the expected output by confirming a new Witcher game is in development by CD Projekt Red, starting a new saga. However, it lacks mention of the game's setting being several years after The Witcher 3: Wild Hunt, which is detailed in the expected output.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext watermark\n",
        "%watermark --machine --python --iversions"
      ],
      "metadata": {
        "id": "OND1Lp4hXFBi",
        "outputId": "532c6b15-89e0-4eb9-cd75-5bf814556c2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The watermark extension is already loaded. To reload it, use:\n",
            "  %reload_ext watermark\n",
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "Compiler    : GCC 11.4.0\n",
            "OS          : Linux\n",
            "Release     : 6.1.85+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "deepeval        : 2.0.5\n",
            "langchain_core  : 0.3.25\n",
            "watermark       : 2.5.0\n",
            "langchain_openai: 0.2.12\n",
            "google          : 2.0.3\n",
            "\n"
          ]
        }
      ]
    }
  ]
}