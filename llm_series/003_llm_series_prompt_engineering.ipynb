{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dependencies"
      ],
      "metadata": {
        "id": "kvZAZbGtuFIR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vICbJ3EmtLGz",
        "outputId": "58888818-1051-4958-b33a-9e21664f3b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-openai langchain_community langchainhub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary modules\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "from langchain import hub\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# provide the API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY4')"
      ],
      "metadata": {
        "id": "jW6Gre3wt6sU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create openai chat model\n",
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "# create basic string output parser\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "-ORbr2xSuEnk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-Shot Prompting"
      ],
      "metadata": {
        "id": "9QRsi9P_t2AV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create prompt template\n",
        "system_template_zero_shot = \"Translate the following english {text} into spanish:\"\n",
        "\n",
        "prompt_template_zero_shot = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template_zero_shot), (\"user\", \"{text}\")]\n",
        ")\n",
        "\n",
        "# using LCEL to create chain\n",
        "chain_zero_shot = prompt_template_zero_shot | model | parser\n",
        "\n",
        "# invoke the chain\n",
        "chain_zero_shot.invoke({\"text\": \"Hello how are you today ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NsFNQXm-twQk",
        "outputId": "aabc1b15-acc5-4ec6-bf53-8089d806bf00"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hola, ¿cómo estás hoy?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few-Shot Prompting"
      ],
      "metadata": {
        "id": "zqcpV3bIuzFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create prompt template\n",
        "system_template_few_shot = \"\"\"\n",
        "Classify the following feedback into 3 sentiment categories (positive, neutral, and negative):\n",
        "\n",
        "Here is some examples for your reference:\n",
        "\n",
        "feedback: The product is amazing and exceeded my expectations\n",
        "output: positive\n",
        "\n",
        "feedback: The delivery was late, and the packaging was damaged\n",
        "output: negative\n",
        "\n",
        "feedback: The product is okay, but the service could be better\n",
        "output: neutral\n",
        "\n",
        "Classify this feedback:\n",
        "\n",
        "feedback: {user_feedback}\n",
        "output:\n",
        "\"\"\"\n",
        "\n",
        "prompt_template_few_shot = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template_few_shot), (\"user\", \"{user_feedback}\")]\n",
        ")\n",
        "\n",
        "# using LCEL to create chain\n",
        "chain_few_shot = prompt_template_few_shot | model | parser\n",
        "\n",
        "# invoke the chain\n",
        "chain_few_shot.invoke({\"user_feedback\": \"this keyboard is very good\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PjI1zIzDu6H_",
        "outputId": "5a2e3060-22b2-427b-ee27-e9c8fb2ea03d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain of Tought"
      ],
      "metadata": {
        "id": "OylW3D7bvObT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create prompt template\n",
        "system_template_cot = \"\"\"\n",
        "You need to answer this user question:\n",
        "\n",
        "user question: {question}\n",
        "output:\n",
        "\n",
        "Lets think step by step\n",
        "\"\"\"\n",
        "\n",
        "prompt_template_cot = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template_cot), (\"user\", \"{question}\")]\n",
        ")\n",
        "\n",
        "# using LCEL to create chain\n",
        "chain_cot = prompt_template_cot | model | parser\n",
        "\n",
        "question = \"\"\"\n",
        "You have two options for travel.\n",
        "- Option A costs $200 and takes 4 hours.\n",
        "- Option B costs $150 but takes 6 hours.\n",
        "Which is better in terms of cost per hour?\n",
        "\"\"\"\n",
        "\n",
        "# invoke the chain\n",
        "chain_cot.invoke({\"question\": question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ppiduI-rvV0C",
        "outputId": "0474079d-4f0e-41b4-a2d3-c05419be7ba5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Let's calculate the cost per hour for each option:\\n\\n- **Option A**: \\n  - Cost: $200\\n  - Time: 4 hours\\n  - Cost per hour = Total cost / Total time = $200 / 4 hours = $50 per hour\\n\\n- **Option B**: \\n  - Cost: $150\\n  - Time: 6 hours\\n  - Cost per hour = Total cost / Total time = $150 / 6 hours = $25 per hour\\n\\nIn terms of cost per hour, Option B is better as it costs $25 per hour compared to Option A which costs $50 per hour.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReAct"
      ],
      "metadata": {
        "id": "auIwEEaovwZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create tools, for this purpose we dont use any tools\n",
        "tools = []\n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "# Construct the ReAct agent\n",
        "agent = create_react_agent(model, tools, prompt)\n",
        "\n",
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "agent_executor.invoke({\"input\" : \"how to use PS4 controller in steam?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ciy3Q9ttvvwJ",
        "outputId": "0e36c8f8-c547-489f-81ec-a6c8f54cb475"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo use a PS4 controller in Steam, you need to follow these steps:\n",
            "\n",
            "1. **Connect Your Controller**: You can connect the PS4 controller to your PC using a USB cable or via Bluetooth. If you're using Bluetooth, ensure that your PC has Bluetooth capability.\n",
            "\n",
            "2. **Enable Steam Input**: \n",
            "   - Open Steam and go to \"Steam\" in the top-left corner.\n",
            "   - Select \"Settings\" from the drop-down menu.\n",
            "   - In the settings menu, click on \"Controller\" and then \"General Controller Settings.\"\n",
            "   - Check the box for \"PlayStation Configuration Support.\" This allows Steam to recognize and use your PS4 controller.\n",
            "\n",
            "3. **Customize Your Controller (Optional)**:\n",
            "   - In the same \"General Controller Settings\" menu, you can customize the button layout and other settings if needed.\n",
            "\n",
            "4. **Launch Your Game**: \n",
            "   - Start the game you want to play, and the PS4 controller should work automatically.\n",
            "   - Some games might have specific controller settings within their own menus, so you might need to configure it further in-game.\n",
            "\n",
            "5. **Troubleshooting**:\n",
            "   - If the controller isn't working, try restarting Steam or reconnecting the controller.\n",
            "   - Ensure your controller firmware is up to date if using it wirelessly.\n",
            "\n",
            "Final Answer: To use a PS4 controller in Steam, connect it via USB or Bluetooth, enable \"PlayStation Configuration Support\" in Steam's controller settings, and your controller should work with Steam games.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'how to use PS4 controller in steam?',\n",
              " 'output': 'To use a PS4 controller in Steam, connect it via USB or Bluetooth, enable \"PlayStation Configuration Support\" in Steam\\'s controller settings, and your controller should work with Steam games.'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ToT"
      ],
      "metadata": {
        "id": "rGw4MiV2x2bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create prompt template ref: https://github.com/dave1010/tree-of-thought-prompting\n",
        "system_template_tot = \"\"\"\n",
        "Imagine three different experts are answering this question.\n",
        "All experts will write down 1 step of their thinking,\n",
        "then share it with the group.\n",
        "Then all experts will go on to the next step, etc.\n",
        "If any expert realises they're wrong at any point then they leave.\n",
        "The question is: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template_tot = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template_tot), (\"user\", \"{question}\")]\n",
        ")\n",
        "\n",
        "# using LCEL to create chain\n",
        "chain_tot = prompt_template_tot | model | parser\n",
        "\n",
        "# invoke the chain\n",
        "chain_tot.invoke({\"question\": \"why the sky is blue ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "eBW_-rcxzOd0",
        "outputId": "822752f8-b11c-4f72-e7fd-660fa7548c71"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Expert 1: The sky appears blue to us because of the way Earth's atmosphere scatters sunlight.\\n\\nExpert 2: Sunlight is made up of different colors of light, each with its own wavelength. When sunlight enters Earth's atmosphere, it collides with air molecules and other small particles.\\n\\nExpert 3: Among the colors of the visible spectrum, blue light has a shorter wavelength and is scattered in all directions by the gases and particles in the atmosphere more than other colors.\\n\\n---\\n\\nExpert 1: This scattering process is known as Rayleigh scattering, named after the British scientist Lord Rayleigh who first described it.\\n\\nExpert 2: Since blue light is scattered in all directions, it is much more likely to reach our eyes, making the sky appear predominantly blue.\\n\\nExpert 3: During sunrise and sunset, the sky can appear red or orange because the sun is lower in the sky and its light passes through more atmosphere, scattering the shorter wavelengths and leaving the longer wavelengths like red and orange.\\n\\n---\\n\\nExpert 1: This phenomenon can also be observed on other planets with atmospheres, where the sky's color is determined by the composition of gases and particles present.\\n\\nExpert 2: Additionally, factors such as pollution and dust can affect the color of the sky by scattering light differently, sometimes leading to more vibrant or hazy appearances.\\n\\nExpert 3: Understanding Rayleigh scattering not only explains why the sky is blue but also contributes to our understanding of optical phenomena like the color of distant mountains or the halo around the sun and moon.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SIoXffdLvvts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ViT2W4oNvvqx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}