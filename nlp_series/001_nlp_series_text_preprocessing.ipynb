{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "f06nt1jtPbec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install contractions emoji langdetect"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8Qcs_1fSYah",
        "outputId": "3949bd1a-726e-4e66-e377-77c2bdd40ada"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/981.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m624.6/981.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "import re\n",
        "import contractions\n",
        "import emoji\n",
        "\n",
        "from langdetect import detect\n",
        "from textblob import TextBlob\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr37iKaZPk8J",
        "outputId": "2e07a74c-7ec6-496b-d252-9ec7153b9565"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V9IfYkeOzF2",
        "outputId": "1634f4ca-22f0-42c3-f244-afe5a2aacc50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Tokens: ['Natural', 'Language', 'Processing', 'is', 'fascinating', '!', 'Let', \"'s\", 'explore', 'it', '.']\n",
            "Sentences: ['Natural Language Processing is fascinating!', \"Let's explore it.\"]\n"
          ]
        }
      ],
      "source": [
        "text = \"Natural Language Processing is fascinating! Let's explore it.\"\n",
        "\n",
        "# Word Tokenization with NLTK\n",
        "nltk_tokens = word_tokenize(text)\n",
        "print(\"NLTK Tokens:\", nltk_tokens)\n",
        "\n",
        "# Sentence Tokenization with NLTK\n",
        "sentences = sent_tokenize(text)\n",
        "print(\"Sentences:\", sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Noise"
      ],
      "metadata": {
        "id": "lHaK3Y6fPjB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stopwords and punctuation\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuation = set(string.punctuation)\n",
        "\n",
        "cleaned_tokens = [\n",
        "    token for token in nltk_tokens\n",
        "    if token.lower() not in stop_words and token not in punctuation\n",
        "]\n",
        "print(\"Cleaned Tokens:\", cleaned_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M5YwJuQPQTn",
        "outputId": "b92e4f88-d7b0-4b2d-df8b-0654d0de1da1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Tokens: ['Natural', 'Language', 'Processing', 'fascinating', 'Let', \"'s\", 'explore']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case Normalization"
      ],
      "metadata": {
        "id": "RAp-89nYP4fP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_lower = text.lower()\n",
        "print(\"Lowercase Text:\", text_lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLugJUukPwdD",
        "outputId": "d86faa05-6edc-48c4-d364-65778423b840"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercase Text: natural language processing is fascinating! let's explore it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming and Lemmatization"
      ],
      "metadata": {
        "id": "70ZkEkWyQBmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#individual word\n",
        "word = \"historical\"\n",
        "stemmed_word = stemmer.stem(word)\n",
        "lemmatized_word = lemmatizer.lemmatize(word)\n",
        "print(\"Stemmed Word:\", stemmed_word)\n",
        "print(\"Lemmatized Word:\", lemmatized_word)\n",
        "\n",
        "#in sentences\n",
        "raw_text = \"The striped bats are hanging on their feet for best\"\n",
        "text_stem = \" \".join([stemmer.stem(word) for word in raw_text.split()])\n",
        "text_lemma = \" \".join([lemmatizer.lemmatize(word) for word in raw_text.split()])\n",
        "print(\"Stemmed Text:\", text_stem)\n",
        "print(\"Lemmatized Text:\", text_lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddsXImowP8p7",
        "outputId": "86056937-a266-49c0-9a27-91476ef99a71"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Word: histor\n",
            "Lemmatized Word: historical\n",
            "Stemmed Text: the stripe bat are hang on their feet for best\n",
            "Lemmatized Text: The striped bat are hanging on their foot for best\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle Numbers and Special Characters"
      ],
      "metadata": {
        "id": "Q1_LmkXcRXFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_with_numbers = \"The price increased by 50% in 2023. What do you think? ğŸ˜Š\"\n",
        "\n",
        "# Remove numbers\n",
        "cleaned_text = re.sub(r'\\d+', '', text_with_numbers)\n",
        "print(\"Cleaned Text:\", cleaned_text)\n",
        "\n",
        "# Count numbers (feature engineering)\n",
        "num_count = len(re.findall(r'\\d+', text_with_numbers))\n",
        "num = re.findall(r'\\d+', text_with_numbers)\n",
        "print(\"Number Count:\", num_count)\n",
        "print(\"Numbers:\", num)\n",
        "\n",
        "# Count special characters like % ? and etc\n",
        "special_count = len(re.findall(r'[^\\w\\s]', text_with_numbers))\n",
        "special = re.findall(r'[^\\w\\s]', text_with_numbers)\n",
        "print(\"Special Character Count:\", special_count)\n",
        "print(\"Special Characters:\", special)\n",
        "\n",
        "# Handle emoji\n",
        "cleaned_text_emoji = emoji.demojize(text_with_numbers)\n",
        "print(\"Cleaned Text with Emoji:\", cleaned_text_emoji)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKm3p0r4QdEI",
        "outputId": "6220ff7c-78e7-43ce-b7ec-3d5d4b7e4e96"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text: The price increased by % in . What do you think? ğŸ˜Š\n",
            "Number Count: 2\n",
            "Numbers: ['50', '2023']\n",
            "Special Character Count: 4\n",
            "Special Characters: ['%', '.', '?', 'ğŸ˜Š']\n",
            "Cleaned Text with Emoji: The price increased by 50% in 2023. What do you think? :smiling_face_with_smiling_eyes:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Contractions and Abbreviations"
      ],
      "metadata": {
        "id": "5AXw37x7STj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I can't wait to see y'all in 2023!\"\n",
        "expanded_text = contractions.fix(text)\n",
        "print(\"Expanded Text:\", expanded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m2Udu9FRv56",
        "outputId": "e10829ef-c5f3-4e5e-d12c-b611140604ab"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expanded Text: I cannot wait to see you all in 2023!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spell Correction"
      ],
      "metadata": {
        "id": "Jn9-Mpu6X4mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"NLP is teh best!\"\n",
        "\n",
        "blob = TextBlob(text)\n",
        "corrected = blob.correct()\n",
        "print(corrected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR4twc88Sfk5",
        "outputId": "c591072e-5dd9-410c-a6a0-2632b1a11531"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP is the best!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Language Detection"
      ],
      "metadata": {
        "id": "wZrJCSc4YYyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Language detection example\n",
        "text = \"Ceci est un exemple en franÃ§ais.\"\n",
        "print(detect(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHQWoK_AX9oC",
        "outputId": "7cfc3ed0-2832-4854-fe56-b0bb1b5cd26a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hiWK8QuJYhEd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}